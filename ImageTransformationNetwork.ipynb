{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation Network\n",
    "This is based on Justic C. Johnson's paper, [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf).\n",
    "Here, we are going to make the proposed network for generating the end image (as in the convolutional neural network the will learn weights in order to efficiently calculate how to create an image based on a style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "![Architecture](./images/transformation-network-table.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # For the transformation network, the authors only used 3x3 convolutions\n",
    "        self.conv = nn.Conv2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.out_channels,\n",
    "                               kernel_size = 3)\n",
    "        self.batch_norm = nn.InstanceNorm2d(self.out_channels, affine=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolution\n",
    "        orig_x = x.clone()\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Second convolution\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        \n",
    "        # Now add the original to the new one (and use center cropping)\n",
    "        # Calulate the different between the size of each feature (in terms \n",
    "        # of height/width) to get the center of the original feature\n",
    "        orig_width = orig_x.size()[2] \n",
    "        new_width = x.size()[2]\n",
    "        diff = orig_width - new_width\n",
    "        \n",
    "        # Add the original to the new (complete the residual block)\n",
    "        x = x + orig_x[:, :,\n",
    "                                 diff//2:(orig_width - diff//2), \n",
    "                                 diff//2:(orig_width - diff//2)]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransformationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageTransformationNetwork, self).__init__()\n",
    "        # Use reflection padding to keep the end shape\n",
    "        self.ref_pad = nn.ReflectionPad2d(40)\n",
    "        \n",
    "        # Initial convolutions\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3,\n",
    "                               out_channels = 32,\n",
    "                               kernel_size = 9,\n",
    "                               padding = 6,\n",
    "                               padding_mode = 'reflect')\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = 64,\n",
    "                               out_channels = 128,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 2)\n",
    "        \n",
    "        # Residual Blocks\n",
    "        self.resblock1 = ResidualBlock(in_channels = 128,\n",
    "                                       out_channels = 128)\n",
    "        \n",
    "        self.resblock2 = ResidualBlock(in_channels = 128,\n",
    "                                       out_channels = 128)\n",
    "        \n",
    "        self.resblock3 = ResidualBlock(in_channels = 128,\n",
    "                                       out_channels = 128)\n",
    "        \n",
    "        self.resblock4 = ResidualBlock(in_channels = 128,\n",
    "                                       out_channels = 128)\n",
    "        \n",
    "        self.resblock5 = ResidualBlock(in_channels = 128,\n",
    "                                       out_channels = 128)\n",
    "        \n",
    "        # Transpose convoltutions\n",
    "        self.trans_conv1 = nn.ConvTranspose2d(in_channels=128,\n",
    "                                             out_channels=64,\n",
    "                                             kernel_size=2,\n",
    "                                             stride=2)\n",
    "        \n",
    "        self.trans_conv2 = nn.ConvTranspose2d(in_channels=64,\n",
    "                                              out_channels=32,\n",
    "                                              kernel_size=2,\n",
    "                                              stride=2)\n",
    "        \n",
    "        # End with one last convolution\n",
    "        self.conv4 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 3,\n",
    "                               kernel_size = 9,\n",
    "                               padding = 4,\n",
    "                               padding_mode = 'reflect')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply reflection padding\n",
    "        x = self.ref_pad(x)\n",
    "        \n",
    "        # Apply the initial convolutions\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Apply the residual blocks\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.resblock5(x)        \n",
    "        \n",
    "        #  Apply the transpose convolutions\n",
    "        x = self.trans_conv1(x)\n",
    "        x = self.trans_conv2(x)\n",
    "        \n",
    "        # Apply the final convolution\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "# Test to confirm the residual network works\n",
    "resblock = ResidualBlock(128, 128)\n",
    "test = torch.randn(2, 128, 84, 84)\n",
    "out = resblock(test)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Test to confirm the transormational network works\n",
    "transformation_net = ImageTransformationNetwork()\n",
    "test = torch.randn(2, 3, 256, 256)\n",
    "out = transformation_net(test)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
