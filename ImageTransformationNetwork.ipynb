{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation Network\n",
    "This is based on Justic C. Johnson's paper, [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf).\n",
    "Here, we are going to make the proposed network for generating the end image (as in the convolutional neural network the will learn weights in order to efficiently calculate how to create an image based on a style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "![Architecture](./images/transformation-network-table.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransformationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageTransformationNetwork, self).__init__()\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        # For the transformation network, the authors only used 3x3 convolutions\n",
    "        self.conv = nn.Conv2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.out_channels,\n",
    "                               kernel_size = 3)\n",
    "        self.batch_norm = nn.BatchNorm2d(self.out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolution\n",
    "        orig_x = x.clone()\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Second convolution\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        \n",
    "        # Now add the original to the new one (and use center cropping)\n",
    "        # Calulate the different between the size of each feature (in terms \n",
    "        # of height/width) to get the center of the original feature\n",
    "        orig_width = orig_x.size()[2] \n",
    "        new_width = x.size()[2]\n",
    "        diff = orig_width - new_width\n",
    "        \n",
    "        # Add the original to the new (complete the residual block)\n",
    "        x = x + orig_x[:, :,\n",
    "                                 diff//2:(orig_width - diff//2), \n",
    "                                 diff//2:(orig_width - diff//2)]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "# Test to confirm the network works\n",
    "\n",
    "resblock = ResidualBlock(128, 128)\n",
    "test = torch.randn(2, 128, 84, 84)\n",
    "out = resblock(test)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
